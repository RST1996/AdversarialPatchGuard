{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled32.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RST1996/AdversarialPatchGuard/blob/main/Untitled40_RST2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.parallel\n",
        "# import torch.backends.cudnn as cudnn\n",
        "# import torch.optim as optim\n",
        "# import torch.utils.data\n",
        "# import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6552YNqOoc0w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# a=np.ones((4,4))\n",
        "# print(a)\n",
        "# print(\"-----------------------------\")\n",
        "# a=np.pad(a, [(1,0 ), (1,0)], mode='constant')\n",
        "# print(a)\n",
        "# # # print(a)\n",
        "# a_t=torch.tensor((a))\n",
        "# print(a_t)\n",
        "# b_t=F.pad(a_t,(2,2,2,2),mode='constant')\n",
        "# print(b_t)"
      ],
      "metadata": {
        "id": "U7vVqo7bm0v6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive._mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "X1f94vvzJpaQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/wielandbrendel/bag-of-local-features-models.git"
      ],
      "metadata": {
        "id": "y_pkaPgVqB8J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bagnets.pytorchnet"
      ],
      "metadata": {
        "id": "dFsflDS7qG6g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "try:\n",
        "  shutil.rmtree(\"logs\")\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "dnhTsb7Bs2A7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "606Ytja8Faak"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from gdrive.MyDrive.adversarial_patch_master.pretrained_models_pytorch import pretrainedmodels\n",
        "\n",
        "from gdrive.MyDrive.adversarial_patch_master.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workers=2\n",
        "epochs=1\n",
        "cuda=True\n",
        "target=84\n",
        "conf_target=0.80\n",
        "max_count=60\n",
        "patch_type='square'\n",
        "patch_size=1\n",
        "train_size=20\n",
        "test_size=10\n",
        "image_size=217\n",
        "plot_all=1\n",
        "# netClassifier='inceptionv3'\n",
        "outf='logs'\n",
        "manualSeed=0\n"
      ],
      "metadata": {
        "id": "x3Ha8lS-ZC5N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    os.makedirs(outf)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "if manualSeed is None:\n",
        "    manualSeed = random.randint(1, 100)\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "np.random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed_all(manualSeed)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if torch.cuda.is_available() and not cuda:\n",
        "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")"
      ],
      "metadata": {
        "id": "5KKMkNUzZtTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53484d99-f8bf-4761-c652-107aa13f26c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert train_size + test_size <= 650, \"Traing set size + Test set size > Total dataset size\"\n",
        "\n",
        "print(\"=> creating model \")\n",
        "netClassifier = bagnets.pytorchnet.bagnet33(pretrained=True)\n",
        "if cuda:\n",
        "    netClassifier.cuda()\n",
        "\n",
        "netClassifier.eval()\n",
        "\n",
        "print('==> Preparing data..')\n",
        "# normalize = transforms.Normalize(mean=netClassifier.mean,\n",
        "#                                  std=netClassifier.std)\n",
        "idx = np.arange(650)\n",
        "np.random.shuffle(idx)\n",
        "training_idx = idx[:train_size]\n",
        "test_idx = idx[train_size:test_size]"
      ],
      "metadata": {
        "id": "Ejmhe1mCaFF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f7deee-894e-4471-9085-07189f2ef82a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> creating model \n",
            "==> Preparing data..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dset.ImageFolder('gdrive/MyDrive/d/imagenet_images', transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(217),\n",
        "                # transforms.Resize(194),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])),\n",
        "    batch_size=1, shuffle=False, sampler=SubsetRandomSampler(training_idx),\n",
        "    num_workers=workers, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dset.ImageFolder('gdrive/MyDrive/d/imagenet_images',  transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(217),\n",
        "                transforms.Resize(209),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])),\n",
        "    batch_size=1, shuffle=False, sampler=SubsetRandomSampler(test_idx),\n",
        "    num_workers=workers, pin_memory=True)\n",
        "\n",
        "# min_in, max_in = netClassifier.input_range[0], netClassifier.input_range[1]\n",
        "# min_in, max_in = np.array([min_in, min_in, min_in]), np.array([max_in, max_in, max_in])\n",
        "# # mean, std = np.array(netClassifier.mean), np.array(netClassifier.std) \n",
        "# min_out, max_out = np.min((min_in-mean)/std), np.max((max_in-mean)/std)"
      ],
      "metadata": {
        "id": "lGdv4ObGbMO9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicto={}\n",
        "dicto[0]=torch.tensor([162])\n",
        "dicto[1]=torch.tensor([309])\n",
        "dicto[2]=torch.tensor([471])\n",
        "dicto[3]=torch.tensor([79])\n",
        "dicto[4]=torch.tensor([134])\n",
        "dicto[5]=torch.tensor([599])\n",
        "dicto[6]=torch.tensor([374])\n",
        "dicto[7]=torch.tensor([656])\n",
        "dicto[8]=torch.tensor([114])\n",
        "dicto[9]=torch.tensor([113])\n",
        "dicto[10]=torch.tensor([866])\n",
        "dicto[11]=torch.tensor([340])\n",
        "for key in dicto:\n",
        "  print(key,dicto[key])\n",
        "# print(dicto[0])\n"
      ],
      "metadata": {
        "id": "6R0fZgN1rEXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b9c008-8657-4892-f561-752041feb44c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([162])\n",
            "1 tensor([309])\n",
            "2 tensor([471])\n",
            "3 tensor([79])\n",
            "4 tensor([134])\n",
            "5 tensor([599])\n",
            "6 tensor([374])\n",
            "7 tensor([656])\n",
            "8 tensor([114])\n",
            "9 tensor([113])\n",
            "10 tensor([866])\n",
            "11 tensor([340])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask=np.zeros((1,3,217,217))\n",
        "ons=np.ones((1,3,217,217))\n",
        "ons=torch.FloatTensor(ons)\n",
        "ons=ons.cuda()\n",
        "\n",
        "for i in range(15):\n",
        "  for j in range(217):\n",
        "    mask[0][0][i][j]=1\n",
        "    mask[0][1][i][j]=1\n",
        "    mask[0][2][i][j]=1\n",
        "for i in range(217):\n",
        "  for j in range(15):\n",
        "    mask[0][0][i][j]=1\n",
        "    mask[0][1][i][j]=1\n",
        "    mask[0][2][i][j]=1\n",
        "for i in range(201,217):\n",
        "  for j in range(217):\n",
        "    mask[0][0][i][j]=1\n",
        "    mask[0][1][i][j]=1\n",
        "    mask[0][2][i][j]=1\n",
        "for i in range(217):\n",
        "  for j in range(201,217):\n",
        "    mask[0][0][i][j]=1\n",
        "    mask[0][1][i][j]=1\n",
        "    mask[0][2][i][j]=1\n",
        "\n",
        "mask=torch.FloatTensor(mask)\n",
        "mask=mask.cuda()"
      ],
      "metadata": {
        "id": "MeeyescrlU_Q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "h5iknJsWahYg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, patch, patch_shape):\n",
        "  global mask\n",
        "  netClassifier.eval()\n",
        "  success = 0\n",
        "  total = 0\n",
        "  recover_time = 0\n",
        "  for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "    # data=F.pad(dataxx,(15,15,15,15),mode='constant')\n",
        "    # print(data.shape)\n",
        "\n",
        "    if cuda:\n",
        "        data = data.cuda()\n",
        "        # for l in labels:\n",
        "        #   print(l)\n",
        "        labels=dicto[labels[0].item()]\n",
        "        labels = labels.cuda()\n",
        "    # data, labels = Variable(data), Variable(labels)\n",
        "    # print(\"aa\",labels)\n",
        "    prediction = netClassifier(data)\n",
        "\n",
        "    # only computer adversarial examples on examples that are originally classified correctly  \n",
        "    # print(prediction.data.max(1)[1][0],labels.data[0])      \n",
        "\n",
        "    if prediction.data.max(1)[1][0] != labels.data[0]:\n",
        "        continue\n",
        "  \n",
        "    total += 1\n",
        "    \n",
        "    # transform path\n",
        "    data_shape = data.data.cpu().numpy().shape\n",
        "    # print(data_shape)\n",
        "    # if patch_type == 'circle':\n",
        "    #     patch, mask, patch_shape = circle_transform(patch, data_shape, patch_shape, image_size)\n",
        "    # elif patch_type == 'square':\n",
        "    #     # patch, mask  = square_transform(patch, data_shape, patch_shape, image_size)\n",
        "    #     pass\n",
        "    patch2 = torch.FloatTensor(copy.deepcopy(patch))\n",
        "    if cuda:\n",
        "        patch2 = patch2.cuda()\n",
        "    # patch2, mask2 = Variable(patcht), Variable(copy.deepcopy(mask))\n",
        "    patch2, mask2 = patch2, mask\n",
        "\n",
        "    adv_x, patch2 = attack(data, patch2)\n",
        "    \n",
        "    adv_label = netClassifier(adv_x).data.max(1)[1][0]\n",
        "    ori_label = labels.data[0]\n",
        "    \n",
        "    if adv_label == target:\n",
        "        success += 1\n",
        "        \n",
        "        if plot_all == 1: \n",
        "            pass\n",
        "            # plot source image\n",
        "            # vutils.save_image(data.data, \"./%s/%d_%d_original.png\" %(outf, batch_idx, ori_label), normalize=True)\n",
        "            \n",
        "            # plot adversarial image\n",
        "            # print(torch.min(adv_x),torch.min(adv_x.data),torch.min(adv_x.data.cpu()))\n",
        "            # print(torch.max(adv_x),torch.max(adv_x.data),torch.max(adv_x.data.cpu()))\n",
        "            # print(\"./%s/%d_%d_adversarial.npy\" %(outf, batch_idx, adv_label))\n",
        "            # ko= adv_x.cpu().data.numpy()\n",
        "            # # print(np.min(ko))\n",
        "            # with open(\"./%s/%d_%d_adversarial.npy\" %(outf, batch_idx, adv_label), 'wb') as f:\n",
        "            #   np.save(f,ko)\n",
        "            # vutils.save_image(adv_x.data, \"gdrive/MyDrive/tt_patch/%d_%d_adversarial.png\" %(batch_idx, adv_label), normalize=True)\n",
        "\n",
        "    masked_patch = torch.mul(mask2, patch2)\n",
        "    patch2 = masked_patch.cpu().data.numpy()\n",
        "    # new_patch = np.zeros(patch_shape)\n",
        "    # for i in range(new_patch.shape[0]): \n",
        "    #     for j in range(new_patch.shape[1]): \n",
        "    #         new_patch[i][j] = patch[i][j]\n",
        "\n",
        "    # patch = new_patch\n",
        "\n",
        "    # log to file  \n",
        "    progress_bar(batch_idx, len(train_loader), \"Train Patch Success: {:.3f}\".format(success/total))\n",
        "\n",
        "  return patch2"
      ],
      "metadata": {
        "id": "eQWfcU1Xne2e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "svB_Gh-J_xpj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch, patch, patch_shape):\n",
        "    global mask\n",
        "    # netClassifier.eval()\n",
        "    success = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, labels) in enumerate(test_loader):\n",
        "        # data=F.pad(dataxx,(15,15,15,15),mode='constant')\n",
        "        if cuda:\n",
        "            data = data.cuda()\n",
        "            labels=dicto[labels[0].item()]\n",
        "            labels = labels.cuda()\n",
        "        # data, labels = Variable(data), Variable(labels)\n",
        "\n",
        "        prediction = netClassifier(data)\n",
        "        # print(prediction.data.max(1)[1][0],labels.data[0])      \n",
        "\n",
        "        # only computer adversarial examples on examples that are originally classified correctly  \n",
        "        # print(prediction.data.max(1)[1][0],labels.data[0])      \n",
        "        if prediction.data.max(1)[1][0] != labels.data[0]:\n",
        "            continue\n",
        "      \n",
        "        total += 1 \n",
        "        \n",
        "        # transform path\n",
        "        data_shape = data.data.cpu().numpy().shape\n",
        "        # if patch_type == 'circle':\n",
        "        #     patch, mask, patch_shape = circle_transform(patch, data_shape, patch_shape, image_size)\n",
        "        # elif patch_type == 'square':\n",
        "        #     # patch, mask = square_transform(patch, data_shape, patch_shape, image_size)\n",
        "        #     pass\n",
        "        patch2 = torch.FloatTensor(copy.deepcopy(patch))\n",
        "        if cuda:\n",
        "            patch2 = patch2.cuda()\n",
        "        # patch2, mask2 = Variable(patcht), Variable(copy.deepcopy(mask))\n",
        "        patch2, mask2 = patch2,mask\n",
        " \n",
        "        adv_x = torch.mul((ons-mask),data) + torch.mul(mask,patch2)\n",
        "        adv_x = torch.clamp(adv_x, 0.0, 1.0)\n",
        "        \n",
        "        adv_label = netClassifier(adv_x).data.max(1)[1][0]\n",
        "        ori_label = labels.data[0]\n",
        "        \n",
        "        if adv_label == target:\n",
        "            success += 1\n",
        "       \n",
        "        masked_patch = torch.mul(mask2, patch2)\n",
        "        patch2 = masked_patch.cpu().data.numpy()\n",
        "        # new_patch = np.zeros(patch_shape)\n",
        "        # for i in range(new_patch.shape[0]): \n",
        "        #     for j in range(new_patch.shape[1]): \n",
        "        #         new_patch[i][j] = patch[i][j]\n",
        " \n",
        "        # patch = new_patch\n",
        "\n",
        "        # log to file  \n",
        "        # progress_bar(batch_idx, len(test_loader), \"Test Success: {:.3f}\".format(success/total))\n",
        "\n"
      ],
      "metadata": {
        "id": "auPxI479nioX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attack(x, patchd):\n",
        "    global mask\n",
        "    netClassifier.eval()\n",
        "\n",
        "    x_out = F.softmax(netClassifier(x))\n",
        "    target_prob = x_out.data[0][target]\n",
        "\n",
        "    adv_x = torch.mul((ons-mask),x) + torch.mul(mask,patchd)\n",
        "    \n",
        "    count = 0 \n",
        "   \n",
        "    while conf_target > target_prob:\n",
        "        count += 1\n",
        "        adv_x = Variable(adv_x.data, requires_grad=True)\n",
        "        adv_out = F.log_softmax(netClassifier(adv_x))\n",
        "       \n",
        "        adv_out_probs, adv_out_labels = adv_out.max(1)\n",
        "        \n",
        "        Loss = -adv_out[0][target]\n",
        "        Loss.backward()\n",
        "     \n",
        "        adv_grad = adv_x.grad.clone()\n",
        "        \n",
        "        adv_x.grad.data.zero_()\n",
        "       \n",
        "        patchd -= adv_grad \n",
        "        patch=  torch.clamp(patchd,0.0,1.0)\n",
        "        adv_x = torch.mul((ons-mask),x) + torch.mul(mask,patch)\n",
        "        adv_x = torch.clamp(adv_x, 0.0, 1.0)\n",
        " \n",
        "        out = F.softmax(netClassifier(adv_x))\n",
        "        target_prob = out.data[0][target]\n",
        "        #y_argmax_prob = out.data.max(1)[0][0]\n",
        "        \n",
        "        #print(count, conf_target, target_prob, y_argmax_prob)  \n",
        "\n",
        "        if count >= max_count:\n",
        "            break\n",
        "\n",
        "\n",
        "    return adv_x, patch \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D-MvWG6Dnta3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qx_bomGu694G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t=1\n",
        "if patch_type == 'circle':\n",
        "    patch, patch_shape = init_patch_circle(image_size, patch_size) \n",
        "elif patch_type == 'square':\n",
        "    patch, patch_shape = init_patch_square(image_size, patch_size) \n",
        "    # print(patch,patch_shape)\n",
        "\n",
        "else:\n",
        "    # sys.exit(\"Please choose a square or circle patch\")\n",
        "    t=0\n",
        "if t:\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      print(epoch)\n",
        "      patch = train(epoch, patch, patch_shape)\n",
        "      test(epoch, patch, patch_shape)"
      ],
      "metadata": {
        "id": "6aFsS394nwMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c66a52-c405-4413-ccd4-5bc80331173b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [=================================>.] Train Patch Success: 0.929 | Step: 2s571ms | Tot: 41s946ms\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt=0\n",
        "for file in os.listdir(\"logs\"):\n",
        "  cnt+=1\n",
        "print(cnt)\n"
      ],
      "metadata": {
        "id": "x0qf6tSuwNZb",
        "outputId": "2bb16c9b-f79b-43d9-feec-fe2eeead4304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"/content/logs/38_859_adversarial.npy\", 'rb') as f:\n",
        "#     batch_t= np.load(f)\n",
        "# # batch_t=np.load('gdrive/MyDrive/ph222.npy')\n",
        "# # batch_t+=zz\n",
        "# print(batch_t.shape)\n",
        "# print(type(batch_t))\n",
        "# print(np.min(batch_t))\n",
        "# # j=np.load(\"/content/logs/90_859_adversarial.npy\")\n",
        "# # print(np.)\n",
        "# with open('gdrive/MyDrive/ph222.npy', 'wb') as f:\n",
        "#   np.save(f,batch_t)"
      ],
      "metadata": {
        "id": "3u0nb61bfqTU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b=torch.tensor(batch_t)"
      ],
      "metadata": {
        "id": "xWmxfaxsdSQD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out = netClassifier(b.cuda())\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "id": "8Hbj8JDjdqJr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download classes text file\n",
        "!wget https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\n",
        "with open('imagenet_classes.txt') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]"
      ],
      "metadata": {
        "id": "jaHLCoP1eGuT",
        "outputId": "9eb75378-9dd0-4c61-d6c3-3cd93d6c3bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-04 11:50:24--  https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21674 (21K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt.7’\n",
            "\n",
            "imagenet_classes.tx 100%[===================>]  21.17K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-01-04 11:50:25 (16.1 MB/s) - ‘imagenet_classes.txt.7’ saved [21674/21674]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# _, indices = torch.sort(out, descending=True)\n",
        "# percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "# [(idx,classes[idx], percentage[idx].item()) for idx in indices[0][:5]]"
      ],
      "metadata": {
        "id": "TXOQDoZ7eAeJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # print(patch.shape)\n",
        "zz=torch.FloatTensor(patch)\n",
        "vutils.save_image(zz, \"a.png\")\n",
        "vutils.save_image(zz, \"ac.jpg\")\n",
        "\n",
        "# jk=torch.tensor(mask)\n",
        "# vutils.save_image(jk.data, \"ab.png\")\n",
        "# print(patch[0][0][220][80])"
      ],
      "metadata": {
        "id": "nS9_v3-w4TN4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('gdrive/MyDrive/paaaaaah84.npy', 'wb') as f:\n",
        "#   np.save(f,patch)"
      ],
      "metadata": {
        "id": "iSHUqrsMMdFy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('gdrive/MyDrive/paaaaaah84.npy', 'rb') as f:\n",
        "#   kkkk=np.load(f)\n",
        "# ll=torch.FloatTensor(kkkk)"
      ],
      "metadata": {
        "id": "Mfh870HfMh6G"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision import transforms\n",
        "# transform = transforms.Compose([            #[1]\n",
        "#  transforms.Resize(256),                    #[2]\n",
        "#  transforms.CenterCrop(224),   \n",
        "#  transforms.Resize(209),                    #[2]\n",
        "#               #[3]\n",
        "#  transforms.ToTensor(),                     #[4]\n",
        "# #  transforms.Normalize(                      #[5]\n",
        "# #  mean=[0.485, 0.456, 0.406],                #[6]\n",
        "# #  std=[0.229, 0.224, 0.225]                  #[7]\n",
        "#  ])"
      ],
      "metadata": {
        "id": "u0SeIy3vkfa2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://upload.wikimedia.org/wikipedia/commons/2/26/YellowLabradorLooking_new.jpg -O dog.jpg"
      ],
      "metadata": {
        "id": "dvSQK_OLkhyS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "# img = Image.open(\"dog.jpg\")\n",
        "# # # img=img.resize((224,224))"
      ],
      "metadata": {
        "id": "6NnygDcaknXL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# img_t = transform(img)\n",
        "# # # for i in range(50,160):\n",
        "# # #   for j in range(50,160):\n",
        "# # #     img_t[0][i][j]=0\n",
        "# # #     img_t[1][i][j]=0\n",
        "# # #     img_t[2][i][j]=0\n",
        "# # # print(img_t.shape)\n",
        "# a=F.pad(img_t,(15,0,15,0), mode='constant')\n",
        "\n",
        "# batch_t = torch.unsqueeze(a, 0)\n",
        "\n",
        "# # data=F.pad(dataxx,(15,0,15,0),mode='constant')\n",
        "# d=batch_t+ll\n",
        "# # d = d.float()\n",
        "# # d=torch.clamp(d,0.0,1.0)\n",
        "# # # print(batch_t.shape)\n",
        "# # # with open('test.npy', 'wb') as f:\n",
        "# # #     np.save(f, batch_t)"
      ],
      "metadata": {
        "id": "TP-88UjekqQB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vutils.save_image(d,\"kll2.jpg\")\n"
      ],
      "metadata": {
        "id": "h1z3X2kecXIP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out = netClassifier(d.cuda())\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "id": "uuyAoWJpk2pB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# _, indices = torch.sort(out, descending=True)\n",
        "# percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "# [(idx,classes[idx], percentage[idx].item()) for idx in indices[0][:5]]"
      ],
      "metadata": {
        "id": "iKDRyeGQlh3x"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}