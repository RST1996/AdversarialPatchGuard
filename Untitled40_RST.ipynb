{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled32.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "125874c9a49b4295a2cc4fb759121cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3200878b5d6043d0a04d88d49ccf8752",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f25e494d73b648729211f2b36c7a6c02",
              "IPY_MODEL_a77ab51a207b466e815ab4f0f18bc837",
              "IPY_MODEL_11fc3289f7df46fa984c41b4b8ec7115"
            ]
          }
        },
        "3200878b5d6043d0a04d88d49ccf8752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f25e494d73b648729211f2b36c7a6c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11e13b3ca249424cb0db20a13bc946c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65123d8cbb094545b9f085725fad43eb"
          }
        },
        "a77ab51a207b466e815ab4f0f18bc837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11bb150f347542139b3b8586d5ba1987",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 73491720,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 73491720,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ca4576e17894eb49b5dddd9ce5aad9a"
          }
        },
        "11fc3289f7df46fa984c41b4b8ec7115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ba0aebd87a684548a4931dba49e5d272",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 70.1M/70.1M [00:00&lt;00:00, 87.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ef1faa5fbe04ea1b247f054b0a8fca8"
          }
        },
        "11e13b3ca249424cb0db20a13bc946c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65123d8cbb094545b9f085725fad43eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11bb150f347542139b3b8586d5ba1987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ca4576e17894eb49b5dddd9ce5aad9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba0aebd87a684548a4931dba49e5d272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ef1faa5fbe04ea1b247f054b0a8fca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RST1996/AdversarialPatchGuard/blob/main/Untitled40_RST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.parallel\n",
        "# import torch.backends.cudnn as cudnn\n",
        "# import torch.optim as optim\n",
        "# import torch.utils.data\n",
        "# import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6552YNqOoc0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# a=np.ones((4,4))\n",
        "# print(a)\n",
        "# print(\"-----------------------------\")\n",
        "# a=np.pad(a, [(1,0 ), (1,0)], mode='constant')\n",
        "# print(a)\n",
        "# # # print(a)\n",
        "# a_t=torch.tensor((a))\n",
        "# print(a_t)\n",
        "# b_t=F.pad(a_t,(2,2,2,2),mode='constant')\n",
        "# print(b_t)"
      ],
      "metadata": {
        "id": "U7vVqo7bm0v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive._mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "X1f94vvzJpaQ",
        "outputId": "638ce906-0432-4553-8a8c-7b34b98442af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/wielandbrendel/bag-of-local-features-models.git"
      ],
      "metadata": {
        "id": "y_pkaPgVqB8J",
        "outputId": "15be51aa-8596-4c06-d30c-ac1b07b2222d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/wielandbrendel/bag-of-local-features-models.git\n",
            "  Cloning https://github.com/wielandbrendel/bag-of-local-features-models.git to /tmp/pip-req-build-0ynda04z\n",
            "  Running command git clone -q https://github.com/wielandbrendel/bag-of-local-features-models.git /tmp/pip-req-build-0ynda04z\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bagnets==0.1) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bagnets==0.1) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from bagnets==0.1) (57.4.0)\n",
            "Building wheels for collected packages: bagnets\n",
            "  Building wheel for bagnets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bagnets: filename=bagnets-0.1-py3-none-any.whl size=7615 sha256=b24311096dc32d45dabb2be043013ca6e0a0c4a4919313d1d3577ceefdc956b1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sp3d29c4/wheels/97/69/7e/bd99c23dc04c4114f18c4e0bde18729259625e49a78d3678c2\n",
            "Successfully built bagnets\n",
            "Installing collected packages: bagnets\n",
            "Successfully installed bagnets-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bagnets.pytorchnet"
      ],
      "metadata": {
        "id": "dFsflDS7qG6g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "try:\n",
        "  shutil.rmtree(\"logs\")\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "dnhTsb7Bs2A7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "606Ytja8Faak"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from gdrive.MyDrive.adversarial_patch_master.pretrained_models_pytorch import pretrainedmodels\n",
        "\n",
        "from gdrive.MyDrive.adversarial_patch_master.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workers=2\n",
        "epochs=4\n",
        "cuda=True\n",
        "target=84\n",
        "conf_target=0.95\n",
        "max_count=60\n",
        "patch_type='square'\n",
        "patch_size=1\n",
        "train_size=200\n",
        "test_size=200\n",
        "image_size=224\n",
        "plot_all=1\n",
        "# netClassifier='inceptionv3'\n",
        "outf='logs'\n",
        "manualSeed=0\n"
      ],
      "metadata": {
        "id": "x3Ha8lS-ZC5N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    os.makedirs(outf)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "if manualSeed is None:\n",
        "    manualSeed = random.randint(1, 100)\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "np.random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed_all(manualSeed)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if torch.cuda.is_available() and not cuda:\n",
        "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")"
      ],
      "metadata": {
        "id": "5KKMkNUzZtTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488a2892-cfad-4083-d2a4-529253373b71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert train_size + test_size <= 650, \"Traing set size + Test set size > Total dataset size\"\n",
        "\n",
        "print(\"=> creating model \")\n",
        "netClassifier = bagnets.pytorchnet.bagnet33(pretrained=True)\n",
        "if cuda:\n",
        "    netClassifier.cuda()\n",
        "\n",
        "netClassifier.eval()\n",
        "\n",
        "print('==> Preparing data..')\n",
        "# normalize = transforms.Normalize(mean=netClassifier.mean,\n",
        "#                                  std=netClassifier.std)\n",
        "idx = np.arange(650)\n",
        "np.random.shuffle(idx)\n",
        "training_idx = idx[:train_size]\n",
        "test_idx = idx[train_size:test_size]"
      ],
      "metadata": {
        "id": "Ejmhe1mCaFF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "125874c9a49b4295a2cc4fb759121cba",
            "3200878b5d6043d0a04d88d49ccf8752",
            "f25e494d73b648729211f2b36c7a6c02",
            "a77ab51a207b466e815ab4f0f18bc837",
            "11fc3289f7df46fa984c41b4b8ec7115",
            "11e13b3ca249424cb0db20a13bc946c3",
            "65123d8cbb094545b9f085725fad43eb",
            "11bb150f347542139b3b8586d5ba1987",
            "4ca4576e17894eb49b5dddd9ce5aad9a",
            "ba0aebd87a684548a4931dba49e5d272",
            "5ef1faa5fbe04ea1b247f054b0a8fca8"
          ]
        },
        "outputId": "adec2fde-cee9-4aa3-baf4-3deebdda7658"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> creating model \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://bitbucket.org/wielandbrendel/bag-of-feature-pretrained-models/raw/249e8fa82c0913623a807d9d35eeab9da7dcc2a8/bagnet32-2ddd53ed.pth.tar\" to /root/.cache/torch/hub/checkpoints/bagnet32-2ddd53ed.pth.tar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "125874c9a49b4295a2cc4fb759121cba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/70.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dset.ImageFolder('gdrive/MyDrive/d/imagenet_images', transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.Resize(209),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])),\n",
        "    batch_size=1, shuffle=False, sampler=SubsetRandomSampler(training_idx),\n",
        "    num_workers=workers, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dset.ImageFolder('gdrive/MyDrive/d/imagenet_images',  transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.Resize(209),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])),\n",
        "    batch_size=1, shuffle=False, sampler=SubsetRandomSampler(test_idx),\n",
        "    num_workers=workers, pin_memory=True)\n",
        "\n",
        "# min_in, max_in = netClassifier.input_range[0], netClassifier.input_range[1]\n",
        "# min_in, max_in = np.array([min_in, min_in, min_in]), np.array([max_in, max_in, max_in])\n",
        "# # mean, std = np.array(netClassifier.mean), np.array(netClassifier.std) \n",
        "# min_out, max_out = np.min((min_in-mean)/std), np.max((max_in-mean)/std)"
      ],
      "metadata": {
        "id": "lGdv4ObGbMO9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicto={}\n",
        "dicto[0]=torch.tensor([162])\n",
        "dicto[1]=torch.tensor([309])\n",
        "dicto[2]=torch.tensor([471])\n",
        "dicto[3]=torch.tensor([79])\n",
        "dicto[4]=torch.tensor([134])\n",
        "dicto[5]=torch.tensor([599])\n",
        "dicto[6]=torch.tensor([374])\n",
        "dicto[7]=torch.tensor([656])\n",
        "dicto[8]=torch.tensor([114])\n",
        "dicto[9]=torch.tensor([113])\n",
        "dicto[10]=torch.tensor([866])\n",
        "dicto[11]=torch.tensor([340])\n",
        "for key in dicto:\n",
        "  print(key,dicto[key])\n",
        "# print(dicto[0])\n"
      ],
      "metadata": {
        "id": "6R0fZgN1rEXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f626bb1-ed4a-4619-98a0-df7190861ba0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([162])\n",
            "1 tensor([309])\n",
            "2 tensor([471])\n",
            "3 tensor([79])\n",
            "4 tensor([134])\n",
            "5 tensor([599])\n",
            "6 tensor([374])\n",
            "7 tensor([656])\n",
            "8 tensor([114])\n",
            "9 tensor([113])\n",
            "10 tensor([866])\n",
            "11 tensor([340])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask=np.zeros((1,3,224,224))\n",
        "ons=np.ones((1,3,224,224))\n",
        "ons=torch.FloatTensor(ons)\n",
        "ons=ons.cuda()\n",
        "\n",
        "for i in range(12):\n",
        "  for j in range(224):\n",
        "    mask[0][0][i][j]=1\n",
        "    mask[0][1][i][j]=1\n",
        "    mask[0][2][i][j]=1\n",
        "for i in range(224):\n",
        "  for j in range(12):\n",
        "    mask[0][0][i][j]=1\n",
        "    mask[0][1][i][j]=1\n",
        "    mask[0][2][i][j]=1\n",
        "for i in range(212,224):\n",
        "  for j in range(224):\n",
        "    mask[0][0][i][j]=1\n",
        "    mask[0][1][i][j]=1\n",
        "    mask[0][2][i][j]=1\n",
        "for i in range(224):\n",
        "  for j in range(212,224):\n",
        "    mask[0][0][i][j]=1\n",
        "    mask[0][1][i][j]=1\n",
        "    mask[0][2][i][j]=1\n",
        "\n",
        "mask=torch.FloatTensor(mask)\n",
        "mask=mask.cuda()"
      ],
      "metadata": {
        "id": "MeeyescrlU_Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "h5iknJsWahYg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, patch, patch_shape):\n",
        "  global mask\n",
        "  netClassifier.eval()\n",
        "  success = 0\n",
        "  total = 0\n",
        "  recover_time = 0\n",
        "  for batch_idx, (dataxx, labels) in enumerate(train_loader):\n",
        "    data=F.pad(dataxx,(15,0,15,0),mode='constant')\n",
        "    # print(data.shape)\n",
        "\n",
        "    if cuda:\n",
        "        data = data.cuda()\n",
        "        # for l in labels:\n",
        "        #   print(l)\n",
        "        labels=dicto[labels[0].item()]\n",
        "        labels = labels.cuda()\n",
        "    data, labels = Variable(data), Variable(labels)\n",
        "    # print(\"aa\",labels)\n",
        "    prediction = netClassifier(data)\n",
        "\n",
        "    # only computer adversarial examples on examples that are originally classified correctly  \n",
        "    # print(prediction.data.max(1)[1][0],labels.data[0])      \n",
        "\n",
        "    if prediction.data.max(1)[1][0] != labels.data[0]:\n",
        "        continue\n",
        "  \n",
        "    total += 1\n",
        "    \n",
        "    # transform path\n",
        "    data_shape = data.data.cpu().numpy().shape\n",
        "    # print(data_shape)\n",
        "    # if patch_type == 'circle':\n",
        "    #     patch, mask, patch_shape = circle_transform(patch, data_shape, patch_shape, image_size)\n",
        "    # elif patch_type == 'square':\n",
        "    #     # patch, mask  = square_transform(patch, data_shape, patch_shape, image_size)\n",
        "    #     pass\n",
        "    patcht = torch.FloatTensor(copy.deepcopy(patch))\n",
        "    if cuda:\n",
        "        patcht = patcht.cuda()\n",
        "    patch2, mask2 = Variable(patcht), Variable(copy.deepcopy(mask))\n",
        "\n",
        "    adv_x, patch2 = attack(data, patch2)\n",
        "    \n",
        "    adv_label = netClassifier(adv_x).data.max(1)[1][0]\n",
        "    ori_label = labels.data[0]\n",
        "    \n",
        "    if adv_label == target:\n",
        "        success += 1\n",
        "        \n",
        "        if plot_all == 1: \n",
        "            pass\n",
        "            # plot source image\n",
        "            # vutils.save_image(data.data, \"./%s/%d_%d_original.png\" %(outf, batch_idx, ori_label), normalize=True)\n",
        "            \n",
        "            # plot adversarial image\n",
        "            # print(torch.min(adv_x),torch.min(adv_x.data),torch.min(adv_x.data.cpu()))\n",
        "            # print(torch.max(adv_x),torch.max(adv_x.data),torch.max(adv_x.data.cpu()))\n",
        "            # print(\"./%s/%d_%d_adversarial.npy\" %(outf, batch_idx, adv_label))\n",
        "            # ko= adv_x.cpu().data.numpy()\n",
        "            # # print(np.min(ko))\n",
        "            # with open(\"./%s/%d_%d_adversarial.npy\" %(outf, batch_idx, adv_label), 'wb') as f:\n",
        "            #   np.save(f,ko)\n",
        "            # vutils.save_image(adv_x.data, \"gdrive/MyDrive/tt_patch/%d_%d_adversarial.png\" %(batch_idx, adv_label), normalize=True)\n",
        "\n",
        "    masked_patch = torch.mul(mask2, patch2)\n",
        "    patch2 = masked_patch.cpu().data.numpy()\n",
        "    # new_patch = np.zeros(patch_shape)\n",
        "    # for i in range(new_patch.shape[0]): \n",
        "    #     for j in range(new_patch.shape[1]): \n",
        "    #         new_patch[i][j] = patch[i][j]\n",
        "\n",
        "    # patch = new_patch\n",
        "\n",
        "    # log to file  \n",
        "    progress_bar(batch_idx, len(train_loader), \"Train Patch Success: {:.3f}\".format(success/total))\n",
        "\n",
        "  return patch"
      ],
      "metadata": {
        "id": "eQWfcU1Xne2e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "svB_Gh-J_xpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch, patch, patch_shape):\n",
        "    global mask\n",
        "    # netClassifier.eval()\n",
        "    success = 0\n",
        "    total = 0\n",
        "    for batch_idx, (dataxx, labels) in enumerate(test_loader):\n",
        "        data=F.pad(dataxx,(15,0,15,0),mode='constant')\n",
        "        if cuda:\n",
        "            data = data.cuda()\n",
        "            labels=dicto[labels[0].item()]\n",
        "            labels = labels.cuda()\n",
        "        data, labels = Variable(data), Variable(labels)\n",
        "\n",
        "        prediction = netClassifier(data)\n",
        "        # print(prediction.data.max(1)[1][0],labels.data[0])      \n",
        "\n",
        "        # only computer adversarial examples on examples that are originally classified correctly  \n",
        "        # print(prediction.data.max(1)[1][0],labels.data[0])      \n",
        "        if prediction.data.max(1)[1][0] != labels.data[0]:\n",
        "            continue\n",
        "      \n",
        "        total += 1 \n",
        "        \n",
        "        # transform path\n",
        "        data_shape = data.data.cpu().numpy().shape\n",
        "        # if patch_type == 'circle':\n",
        "        #     patch, mask, patch_shape = circle_transform(patch, data_shape, patch_shape, image_size)\n",
        "        # elif patch_type == 'square':\n",
        "        #     # patch, mask = square_transform(patch, data_shape, patch_shape, image_size)\n",
        "        #     pass\n",
        "        patcht = torch.FloatTensor(copy.deepcopy(patch))\n",
        "        if cuda:\n",
        "            patcht = patcht.cuda()\n",
        "        patch2, mask2 = Variable(patcht), Variable(copy.deepcopy(mask))\n",
        " \n",
        "        adv_x = torch.mul((ons-mask2),data) + torch.mul(mask2,patch2)\n",
        "        adv_x = torch.clamp(adv_x, 0.0, 1.0)\n",
        "        \n",
        "        adv_label = netClassifier(adv_x).data.max(1)[1][0]\n",
        "        ori_label = labels.data[0]\n",
        "        \n",
        "        if adv_label == target:\n",
        "            success += 1\n",
        "       \n",
        "        masked_patch = torch.mul(mask2, patch2)\n",
        "        patch = masked_patch.cpu().data.numpy()\n",
        "        # new_patch = np.zeros(patch_shape)\n",
        "        # for i in range(new_patch.shape[0]): \n",
        "        #     for j in range(new_patch.shape[1]): \n",
        "        #         new_patch[i][j] = patch[i][j]\n",
        " \n",
        "        # patch = new_patch\n",
        "\n",
        "        # log to file  \n",
        "        # progress_bar(batch_idx, len(test_loader), \"Test Success: {:.3f}\".format(success/total))\n",
        "\n"
      ],
      "metadata": {
        "id": "auPxI479nioX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attack(x, patchd):\n",
        "    global mask\n",
        "    netClassifier.eval()\n",
        "\n",
        "    x_out = F.softmax(netClassifier(x))\n",
        "    target_prob = x_out.data[0][target]\n",
        "\n",
        "    adv_x = torch.mul((ons-mask),x) + torch.mul(mask,patchd)\n",
        "    \n",
        "    count = 0 \n",
        "   \n",
        "    while conf_target > target_prob:\n",
        "        count += 1\n",
        "        adv_x = Variable(adv_x.data, requires_grad=True)\n",
        "        adv_out = F.log_softmax(netClassifier(adv_x))\n",
        "       \n",
        "        adv_out_probs, adv_out_labels = adv_out.max(1)\n",
        "        \n",
        "        Loss = -adv_out[0][target]\n",
        "        Loss.backward()\n",
        "     \n",
        "        adv_grad = adv_x.grad.clone()\n",
        "        \n",
        "        adv_x.grad.data.zero_()\n",
        "       \n",
        "        patchd -= adv_grad \n",
        "        patch=  torch.clamp(patchd,0.0,1.0)\n",
        "        adv_x = torch.mul((ons-mask),x) + torch.mul(mask,patch)\n",
        "        adv_x = torch.clamp(adv_x, 0.0, 1.0)\n",
        " \n",
        "        out = F.softmax(netClassifier(adv_x))\n",
        "        target_prob = out.data[0][target]\n",
        "        #y_argmax_prob = out.data.max(1)[0][0]\n",
        "        \n",
        "        #print(count, conf_target, target_prob, y_argmax_prob)  \n",
        "\n",
        "        if count >= max_count:\n",
        "            break\n",
        "\n",
        "\n",
        "    return adv_x, patch \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D-MvWG6Dnta3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=1\n",
        "if patch_type == 'circle':\n",
        "    patch, patch_shape = init_patch_circle(image_size, patch_size) \n",
        "elif patch_type == 'square':\n",
        "    patch, patch_shape = init_patch_square(image_size, patch_size) \n",
        "    # print(patch,patch_shape)\n",
        "\n",
        "else:\n",
        "    # sys.exit(\"Please choose a square or circle patch\")\n",
        "    t=0\n",
        "if t:\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      print(epoch)\n",
        "      patch = train(epoch, patch, patch_shape)\n",
        "      test(epoch, patch, patch_shape)"
      ],
      "metadata": {
        "id": "6aFsS394nwMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b6ebd8-6f1b-48a8-e172-68f7614610dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "224\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [==================================>] Train Patch Success: 0.936 | Step: 10s465ms | Tot: 22m38s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 200/200 \n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt=0\n",
        "for file in os.listdir(\"logs\"):\n",
        "  cnt+=1\n",
        "print(cnt)\n"
      ],
      "metadata": {
        "id": "x0qf6tSuwNZb",
        "outputId": "0d26a120-aa5c-4b25-c454-bc06a9588ad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"/content/logs/38_859_adversarial.npy\", 'rb') as f:\n",
        "#     batch_t= np.load(f)\n",
        "# # batch_t=np.load('gdrive/MyDrive/ph222.npy')\n",
        "# # batch_t+=zz\n",
        "# print(batch_t.shape)\n",
        "# print(type(batch_t))\n",
        "# print(np.min(batch_t))\n",
        "# # j=np.load(\"/content/logs/90_859_adversarial.npy\")\n",
        "# # print(np.)\n",
        "# with open('gdrive/MyDrive/ph222.npy', 'wb') as f:\n",
        "#   np.save(f,batch_t)"
      ],
      "metadata": {
        "id": "3u0nb61bfqTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b=torch.tensor(batch_t)"
      ],
      "metadata": {
        "id": "xWmxfaxsdSQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out = netClassifier(b.cuda())\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "id": "8Hbj8JDjdqJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download classes text file\n",
        "!wget https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\n",
        "with open('imagenet_classes.txt') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]"
      ],
      "metadata": {
        "id": "jaHLCoP1eGuT",
        "outputId": "3e813112-3e9b-4bfb-f875-23d86022fffe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-21 09:49:14--  https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21674 (21K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "\rimagenet_classes.tx   0%[                    ]       0  --.-KB/s               \rimagenet_classes.tx 100%[===================>]  21.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-21 09:49:14 (43.7 MB/s) - ‘imagenet_classes.txt’ saved [21674/21674]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# _, indices = torch.sort(out, descending=True)\n",
        "# percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "# [(idx,classes[idx], percentage[idx].item()) for idx in indices[0][:5]]"
      ],
      "metadata": {
        "id": "TXOQDoZ7eAeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # print(patch.shape)\n",
        "zz=torch.FloatTensor(patch)\n",
        "vutils.save_image(zz, \"a.png\")\n",
        "vutils.save_image(zz, \"ac.jpg\")\n",
        "\n",
        "# jk=torch.tensor(mask)\n",
        "# vutils.save_image(jk.data, \"ab.png\")\n",
        "# print(patch[0][0][220][80])"
      ],
      "metadata": {
        "id": "nS9_v3-w4TN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('gdrive/MyDrive/paaaaaah84.npy', 'wb') as f:\n",
        "#   np.save(f,patch)"
      ],
      "metadata": {
        "id": "iSHUqrsMMdFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('gdrive/MyDrive/paaaaaah84.npy', 'rb') as f:\n",
        "#   kkkk=np.load(f)\n",
        "# ll=torch.FloatTensor(kkkk)"
      ],
      "metadata": {
        "id": "Mfh870HfMh6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision import transforms\n",
        "# transform = transforms.Compose([            #[1]\n",
        "#  transforms.Resize(256),                    #[2]\n",
        "#  transforms.CenterCrop(224),   \n",
        "#  transforms.Resize(209),                    #[2]\n",
        "#               #[3]\n",
        "#  transforms.ToTensor(),                     #[4]\n",
        "# #  transforms.Normalize(                      #[5]\n",
        "# #  mean=[0.485, 0.456, 0.406],                #[6]\n",
        "# #  std=[0.229, 0.224, 0.225]                  #[7]\n",
        "#  ])"
      ],
      "metadata": {
        "id": "u0SeIy3vkfa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://upload.wikimedia.org/wikipedia/commons/2/26/YellowLabradorLooking_new.jpg -O dog.jpg"
      ],
      "metadata": {
        "id": "dvSQK_OLkhyS",
        "outputId": "444af0be-7994-400f-8dea-3cd10b273b6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-21 09:49:14--  https://upload.wikimedia.org/wikipedia/commons/2/26/YellowLabradorLooking_new.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.153.240, 2620:0:860:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.153.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83281 (81K) [image/jpeg]\n",
            "Saving to: ‘dog.jpg’\n",
            "\n",
            "\rdog.jpg               0%[                    ]       0  --.-KB/s               \rdog.jpg             100%[===================>]  81.33K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-12-21 09:49:14 (1.44 MB/s) - ‘dog.jpg’ saved [83281/83281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "# img = Image.open(\"dog.jpg\")\n",
        "# # # img=img.resize((224,224))"
      ],
      "metadata": {
        "id": "6NnygDcaknXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# img_t = transform(img)\n",
        "# # # for i in range(50,160):\n",
        "# # #   for j in range(50,160):\n",
        "# # #     img_t[0][i][j]=0\n",
        "# # #     img_t[1][i][j]=0\n",
        "# # #     img_t[2][i][j]=0\n",
        "# # # print(img_t.shape)\n",
        "# a=F.pad(img_t,(15,0,15,0), mode='constant')\n",
        "\n",
        "# batch_t = torch.unsqueeze(a, 0)\n",
        "\n",
        "# # data=F.pad(dataxx,(15,0,15,0),mode='constant')\n",
        "# d=batch_t+ll\n",
        "# # d = d.float()\n",
        "# # d=torch.clamp(d,0.0,1.0)\n",
        "# # # print(batch_t.shape)\n",
        "# # # with open('test.npy', 'wb') as f:\n",
        "# # #     np.save(f, batch_t)"
      ],
      "metadata": {
        "id": "TP-88UjekqQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vutils.save_image(d,\"kll2.jpg\")\n"
      ],
      "metadata": {
        "id": "h1z3X2kecXIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out = netClassifier(d.cuda())\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "id": "uuyAoWJpk2pB",
        "outputId": "e69fb938-c2f8-4160-ed02-f386bba5dc64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# _, indices = torch.sort(out, descending=True)\n",
        "# percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "# [(idx,classes[idx], percentage[idx].item()) for idx in indices[0][:5]]"
      ],
      "metadata": {
        "id": "iKDRyeGQlh3x",
        "outputId": "164ab709-9022-44fb-b6e1-d96662fb5168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor(84, device='cuda:0'), 'peacock', 99.99957275390625),\n",
              " (tensor(42, device='cuda:0'), 'agama', 0.00021772760374005884),\n",
              " (tensor(95, device='cuda:0'), 'jacamar', 0.00010537679918343201),\n",
              " (tensor(14, device='cuda:0'),\n",
              "  'indigo bunting, indigo finch, indigo bird, Passerina cyanea',\n",
              "  4.4493648601928726e-05),\n",
              " (tensor(92, device='cuda:0'), 'bee eater', 2.7761432647821493e-05)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}